{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from pandas import read_csv,DataFrame\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=read_csv(\"../data/california_housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after using isna it turns out that there is no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "isMissing=data.isna().any().any()\n",
    "print(isMissing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. standardizing the features\n",
    "2. creating a dataframe from numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(\"MedianHouseValue\",axis=1)\n",
    "y=data[\"MedianHouseValue\"]\n",
    "scaler=StandardScaler()\n",
    "scaledXNP=scaler.fit_transform(x)\n",
    "scaledXDF=DataFrame(scaledXNP,columns=x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the first part we only going to focus on using one feature which is `MedInc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=scaledXDF[\"MedInc\"]\n",
    "x0Train,x0Test,y0Train,y0Test=train_test_split(x0,y,random_state=42,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training a linear regression model using just `MedInc` feature and testing it performance with mse.\n",
    "\n",
    "**Note**: the fit function expect a matrix so we need to reshape the x0Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6917979868048499 2.066968142764858\n"
     ]
    }
   ],
   "source": [
    "model0=LinearRegression()\n",
    "model0.fit(x0Train.values.reshape(-1,1),y0Train)\n",
    "pred0=model0.predict(X=x0Test.values.reshape(-1,1))\n",
    "error0=mean_squared_error(y_true=y0Test,y_pred=pred0)\n",
    "print(error0,np.mean(y0Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The error1 is more than a quarter of the y0Test mean which is quite substantiel\n",
    "2. We going to include the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5305677824766754 2.066968142764858\n"
     ]
    }
   ],
   "source": [
    "x1Train,x1Test,y1Train,y1Test=train_test_split(scaledXDF,y,random_state=42,test_size=0.3)\n",
    "model1=LinearRegression()\n",
    "model1.fit(x1Train,y1Train)\n",
    "pred1=model1.predict(X=x1Test)\n",
    "error1=mean_squared_error(y_true=y1Test,y_pred=pred1)\n",
    "print(error1,np.mean(y1Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we have used all the features that did not result in a big improvment from result of the last model just a difference of `1.6`\n",
    "\n",
    "What we can do now is try transforming our features to polynomial in order to reduce the error.To be clear here applying polynomial transform with a degree=2 to all features gives the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45497233748568755 2.066968142764858\n"
     ]
    }
   ],
   "source": [
    "model2=make_pipeline(PolynomialFeatures(2),LinearRegression())\n",
    "model2.fit(x1Train,y1Train)\n",
    "pred2=model2.predict(X=x1Test)\n",
    "error2=mean_squared_error(y_true=y1Test,y_pred=pred2)\n",
    "print(error2,np.mean(y1Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the error has decreased not with a big margin.\n",
    "\n",
    "**Note**: even though after plotting multiple graphs for featureX/target it seems some of them has no effect on the `medianHouseValue` removing them however will actually have negative impact on the error \n",
    "\n",
    "The final error will be `0.504` if we drop AveOccup."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
